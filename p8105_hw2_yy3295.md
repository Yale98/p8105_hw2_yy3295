p8105_hw2_yy3295
================
Ye Yuan
2023-10-04

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

\##Problem 1 We clean the 538 `pols` data, which provides information on
the number of national politicians who are democratic or republican at
any given time. There are some values for which `prez_gop` is `2` –
these are months in which Ford became President following Nixon’s
resignation. In the new `president` variable created as part of our data
cleaning, we code these as `gop` (same as values when `prez_gop` is
`1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv(
    "data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

    ## Joining with `by = join_by(month_num)`

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

\#Problem 2 Read and clean the Mr. Trash Wheel sheet: specify the sheet
in the Excel file and to omit non-data entries using arguments in
read_excel use reasonable variable names omit rows that do not include
dumpster-specific data

``` r
Mr_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", range = "A2:N586") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("MTW"),
         year = as.numeric(year)) |>
  relocate(dumpster, wheel_type)

Mr_TW_df
```

    ## # A tibble: 584 × 15
    ##    dumpster wheel_type month  year date                weight_tons
    ##       <dbl> <chr>      <chr> <dbl> <dttm>                    <dbl>
    ##  1        1 MTW        May    2014 2014-05-16 00:00:00        4.31
    ##  2        2 MTW        May    2014 2014-05-16 00:00:00        2.74
    ##  3        3 MTW        May    2014 2014-05-16 00:00:00        3.45
    ##  4        4 MTW        May    2014 2014-05-17 00:00:00        3.1 
    ##  5        5 MTW        May    2014 2014-05-17 00:00:00        4.06
    ##  6        6 MTW        May    2014 2014-05-20 00:00:00        2.71
    ##  7        7 MTW        May    2014 2014-05-21 00:00:00        1.91
    ##  8        8 MTW        May    2014 2014-05-28 00:00:00        3.7 
    ##  9        9 MTW        June   2014 2014-06-05 00:00:00        2.52
    ## 10       10 MTW        June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

Import, clean, and organize the data for Professor Trash Wheel

``` r
Prof_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("PTW")) |>
  relocate(dumpster, wheel_type)

Prof_TW_df
```

    ## # A tibble: 106 × 14
    ##    dumpster wheel_type month     year date                weight_tons
    ##       <dbl> <chr>      <chr>    <dbl> <dttm>                    <dbl>
    ##  1        1 PTW        January   2017 2017-01-02 00:00:00        1.79
    ##  2        2 PTW        January   2017 2017-01-30 00:00:00        1.58
    ##  3        3 PTW        February  2017 2017-02-26 00:00:00        2.32
    ##  4        4 PTW        February  2017 2017-02-26 00:00:00        3.72
    ##  5        5 PTW        February  2017 2017-02-28 00:00:00        1.45
    ##  6        6 PTW        March     2017 2017-03-30 00:00:00        1.71
    ##  7        7 PTW        April     2017 2017-04-01 00:00:00        1.82
    ##  8        8 PTW        April     2017 2017-04-20 00:00:00        2.37
    ##  9        9 PTW        May       2017 2017-05-10 00:00:00        2.64
    ## 10       10 PTW        May       2017 2017-05-26 00:00:00        2.78
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>

Import, clean, and organize the data for Gwynnda Trash Wheel

``` r
Gwynnda_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("GTW")) |>
  relocate(dumpster, wheel_type)

Gwynnda_TW_df
```

    ## # A tibble: 155 × 13
    ##    dumpster wheel_type month   year date                weight_tons
    ##       <dbl> <chr>      <chr>  <dbl> <dttm>                    <dbl>
    ##  1        1 GTW        July    2021 2021-07-03 00:00:00        0.93
    ##  2        2 GTW        July    2021 2021-07-07 00:00:00        2.26
    ##  3        3 GTW        July    2021 2021-07-07 00:00:00        1.62
    ##  4        4 GTW        July    2021 2021-07-16 00:00:00        1.76
    ##  5        5 GTW        July    2021 2021-07-30 00:00:00        1.53
    ##  6        6 GTW        August  2021 2021-08-11 00:00:00        2.06
    ##  7        7 GTW        August  2021 2021-08-14 00:00:00        1.9 
    ##  8        8 GTW        August  2021 2021-08-16 00:00:00        2.16
    ##  9        9 GTW        August  2021 2021-08-16 00:00:00        2.6 
    ## 10       10 GTW        August  2021 2021-08-17 00:00:00        3.21
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

Combine the Professor and Gwynnda Trash Wheel with the Mr. Trash Wheel
dataset to produce a single tidy dataset

``` r
Final_TW_df = bind_rows(Mr_TW_df, Prof_TW_df, Gwynnda_TW_df)

Final_TW_df
```

    ## # A tibble: 845 × 15
    ##    dumpster wheel_type month  year date                weight_tons
    ##       <dbl> <chr>      <chr> <dbl> <dttm>                    <dbl>
    ##  1        1 MTW        May    2014 2014-05-16 00:00:00        4.31
    ##  2        2 MTW        May    2014 2014-05-16 00:00:00        2.74
    ##  3        3 MTW        May    2014 2014-05-16 00:00:00        3.45
    ##  4        4 MTW        May    2014 2014-05-17 00:00:00        3.1 
    ##  5        5 MTW        May    2014 2014-05-17 00:00:00        4.06
    ##  6        6 MTW        May    2014 2014-05-20 00:00:00        2.71
    ##  7        7 MTW        May    2014 2014-05-21 00:00:00        1.91
    ##  8        8 MTW        May    2014 2014-05-28 00:00:00        3.7 
    ##  9        9 MTW        June   2014 2014-06-05 00:00:00        2.52
    ## 10       10 MTW        June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

Write a paragraph about these data.

In Mr.Trash Wheel data set, there are 584 rows and 16 cols. The key
variables are wheel_type, dumpster, weight_tons, homes_powered. In
Professor Trash Wheel data set, there are 106 rows and 14 cols. The key
variables are wheel_type, dumpster, weight_tons, homes_powered. In
Gwynnda Trash Wheel data set, there are 155 rows and 13 cols. The key
variables are wheel_type, dumpster, weight_tons, homes_powered. In the
final combined Trash Wheel data set, there are 845 rows and 15 cols. The
key variables are wheel_type, dumpster, weight_tons, homes_powered. The
total weight of trash collected by Professor Trash Wheel were 216.26
tons.

``` r
filter(Final_TW_df, wheel_type == "PTW") |>
  pull(weight_tons) |>
  sum()
```

    ## [1] 216.26

The total number of cigarette butts collected by Gwynnda in July of 2021
are 16300.

``` r
filter(Final_TW_df, wheel_type == "GTW", year == "2021", month == "July") |>
  pull(cigarette_butts) |>
  sum()
```

    ## [1] 16300

\#Problem 3 Import, clean, and tidy the dataset of baseline
demographics. Ensure that sex and APOE4 carrier status are appropriate
encoded (i.e. not numeric), and remove any participants who do not meet
the stated inclusion criteria (i.e. no MCI at baseline).

``` r
MCI_Base = 
  read_csv("data/MCI_baseline.csv", skip = 1, na = c(".")) |>
  janitor::clean_names() |>
  mutate(sex = case_match(sex, 1 ~ "male", 0 ~ "female"),
         apoe4 = case_match(apoe4, 1 ~ "positive", 0 ~ "negative"))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): ID, Current Age, Sex, Education, apoe4, Age at onset
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
MCI_Base
```

    ## # A tibble: 483 × 6
    ##       id current_age sex    education apoe4    age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>           <dbl>
    ##  1     1        63.1 female        16 positive         NA  
    ##  2     2        65.6 female        20 positive         NA  
    ##  3     3        62.5 male          16 positive         66.8
    ##  4     4        69.8 female        16 negative         NA  
    ##  5     5        66   male          16 negative         68.7
    ##  6     6        62.5 male          16 negative         NA  
    ##  7     7        66.5 male          18 negative         74  
    ##  8     8        67.2 female        18 negative         NA  
    ##  9     9        66.7 female        16 negative         NA  
    ## 10    10        64.1 female        18 negative         NA  
    ## # ℹ 473 more rows

There are 483 individuals at first.

Discuss important steps in the import process and relevant features of
the dataset. 1. import the data and clean names. 2. drop participants
who do not meet the stated inclusion criteria 3. mutate sex and APOE4
carrier status to make sure they are not numeric.

``` r
MCI_Base_1 = 
  MCI_Base |>
  filter(age_at_onset - current_age > 0 | is.na(age_at_onset))

MCI_Base_1
```

    ## # A tibble: 479 × 6
    ##       id current_age sex    education apoe4    age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>           <dbl>
    ##  1     1        63.1 female        16 positive         NA  
    ##  2     2        65.6 female        20 positive         NA  
    ##  3     3        62.5 male          16 positive         66.8
    ##  4     4        69.8 female        16 negative         NA  
    ##  5     5        66   male          16 negative         68.7
    ##  6     6        62.5 male          16 negative         NA  
    ##  7     7        66.5 male          18 negative         74  
    ##  8     8        67.2 female        18 negative         NA  
    ##  9     9        66.7 female        16 negative         NA  
    ## 10    10        64.1 female        18 negative         NA  
    ## # ℹ 469 more rows

How many participants were recruited, and of these how many developed
MCI? There are 479 individuals when we remove the individuals who
already have MCI at baseline.

``` r
MCI_Base_2 = 
  MCI_Base |>
  filter(age_at_onset - current_age > 0)

MCI_Base_2
```

    ## # A tibble: 93 × 6
    ##       id current_age sex    education apoe4    age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>           <dbl>
    ##  1     3        62.5 male          16 positive         66.8
    ##  2     5        66   male          16 negative         68.7
    ##  3     7        66.5 male          18 negative         74  
    ##  4    13        63.1 male          12 positive         69  
    ##  5    14        58.4 female        20 negative         66.2
    ##  6    18        67.8 male          16 negative         69.8
    ##  7    22        67.3 female        20 positive         74.6
    ##  8    26        64.8 female        20 positive         71.1
    ##  9    30        66.3 female        12 negative         73.1
    ## 10    39        68.3 female        16 positive         70.2
    ## # ℹ 83 more rows

How many participants were recruited, and of these how many developed
MCI? There are 93 individuals who developed MCI.

``` r
mean(MCI_Base_1$current_age)
```

    ## [1] 65.0286

What is the average baseline age? The average baseline age is 65 years
old.

``` r
nrow(filter(MCI_Base_1, apoe4 == "positive", sex == "female")) /
  nrow(filter(MCI_Base_1, sex == "female"))
```

    ## [1] 0.3

What proportion of women in the study are APOE4 carriers? 0.3 of women
in the study are APOE4 carriers

``` r
MCI_Amy = 
  read_csv("data/MCI_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(time_0 = baseline, id = study_id) |>
  pivot_longer(time_0:time_8,
               names_to = "follow_up_time",
               values_to = "apoe4")
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
MCI_Amy
```

    ## # A tibble: 2,435 × 3
    ##       id follow_up_time apoe4      
    ##    <dbl> <chr>          <chr>      
    ##  1     1 time_0         0.1105487  
    ##  2     1 time_2         <NA>       
    ##  3     1 time_4         0.109325197
    ##  4     1 time_6         0.104756131
    ##  5     1 time_8         0.107257697
    ##  6     2 time_0         0.107481183
    ##  7     2 time_2         0.109157373
    ##  8     2 time_4         0.109457839
    ##  9     2 time_6         0.105729713
    ## 10     2 time_8         0.10661845 
    ## # ℹ 2,425 more rows

Discuss important steps in the import process and relevant features of
the dataset. 1. import the data and clean names. 2. rename baseline to
time_0 for consistency 3. use pivot_longer to tidy the data There are
total of 2435 observations in the data MCI_Amy.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
Baseline = anti_join(MCI_Base_1, MCI_Amy, by = "id")
Amy = anti_join(MCI_Amy, MCI_Base_1, by = "id")
Merge_MCI = inner_join(MCI_Base_1, MCI_Amy, by = "id")

Baseline
```

    ## # A tibble: 8 × 6
    ##      id current_age sex    education apoe4    age_at_onset
    ##   <dbl>       <dbl> <chr>      <dbl> <chr>           <dbl>
    ## 1    14        58.4 female        20 negative         66.2
    ## 2    49        64.7 male          16 negative         68.4
    ## 3    92        68.6 female        20 negative         NA  
    ## 4   179        68.1 male          16 negative         NA  
    ## 5   268        61.4 female        18 positive         67.5
    ## 6   304        63.8 female        16 negative         NA  
    ## 7   389        59.3 female        16 negative         NA  
    ## 8   412        67   male          16 positive         NA

``` r
Amy
```

    ## # A tibble: 80 × 3
    ##       id follow_up_time apoe4      
    ##    <dbl> <chr>          <chr>      
    ##  1    72 time_0         0.106965463
    ##  2    72 time_2         <NA>       
    ##  3    72 time_4         0.107266218
    ##  4    72 time_6         0.106665207
    ##  5    72 time_8         <NA>       
    ##  6   234 time_0         0.110521689
    ##  7   234 time_2         0.110988335
    ##  8   234 time_4         0.110318671
    ##  9   234 time_6         0.107334344
    ## 10   234 time_8         0.108868811
    ## # ℹ 70 more rows

``` r
Merge_MCI
```

    ## # A tibble: 2,355 × 8
    ##       id current_age sex   education apoe4.x age_at_onset follow_up_time apoe4.y
    ##    <dbl>       <dbl> <chr>     <dbl> <chr>          <dbl> <chr>          <chr>  
    ##  1     1        63.1 fema…        16 positi…           NA time_0         0.1105…
    ##  2     1        63.1 fema…        16 positi…           NA time_2         <NA>   
    ##  3     1        63.1 fema…        16 positi…           NA time_4         0.1093…
    ##  4     1        63.1 fema…        16 positi…           NA time_6         0.1047…
    ##  5     1        63.1 fema…        16 positi…           NA time_8         0.1072…
    ##  6     2        65.6 fema…        20 positi…           NA time_0         0.1074…
    ##  7     2        65.6 fema…        20 positi…           NA time_2         0.1091…
    ##  8     2        65.6 fema…        20 positi…           NA time_4         0.1094…
    ##  9     2        65.6 fema…        20 positi…           NA time_6         0.1057…
    ## 10     2        65.6 fema…        20 positi…           NA time_8         0.1066…
    ## # ℹ 2,345 more rows

There are 8 participants in the baseline data but not in the amyloid
data. (ID: 14, 49, 92, 179, 268, 304, 389, 412) There are 16
participants in the amyloid data but no in the baseline data. (ID: 72,
234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,
495) There are 2355 observations appeared in both data sets, which means
that there are 2355/5=471 participants.

``` r
write.csv(Merge_MCI, "Merge_MCI.csv")
```
