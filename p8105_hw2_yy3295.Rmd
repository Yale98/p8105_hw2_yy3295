---
title: "p8105_hw2_yy3295"
author: "Ye Yuan"
date: "2023-10-04"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

##Problem 1
We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv(
    "data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

#Problem 2
Read and clean the Mr. Trash Wheel sheet:
specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
use reasonable variable names
omit rows that do not include dumpster-specific data

```{r}
Mr_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", range = "A2:N586") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("MTW"),
         year = as.numeric(year)) |>
  relocate(dumpster, wheel_type)

Mr_TW_df
```

Import, clean, and organize the data for Professor Trash Wheel

```{r}
Prof_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("PTW")) |>
  relocate(dumpster, wheel_type)

Prof_TW_df
```

Import, clean, and organize the data for Gwynnda Trash Wheel

```{r}
Gwynnda_TW_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_type = c("GTW")) |>
  relocate(dumpster, wheel_type)

Gwynnda_TW_df
```

Combine the Professor and Gwynnda Trash Wheel with the Mr. Trash Wheel dataset to produce a single tidy dataset

```{r}
Final_TW_df = bind_rows(Mr_TW_df, Prof_TW_df, Gwynnda_TW_df)

Final_TW_df
```

Write a paragraph about these data.

In Mr.Trash Wheel data set, there are 584 rows and 16 cols. The key variables are wheel_type, dumpster, weight_tons, homes_powered.
In Professor Trash Wheel data set, there are 106 rows and 14 cols. The key variables are wheel_type, dumpster, weight_tons, homes_powered.
In Gwynnda Trash Wheel data set, there are 155 rows and 13 cols. The key variables are wheel_type, dumpster, weight_tons, homes_powered.
In the final combined Trash Wheel data set, there are 845 rows and 15 cols. The key variables are wheel_type, dumpster, weight_tons, homes_powered.
The total weight of trash collected by Professor Trash Wheel were 216.26 tons.

```{r}
filter(Final_TW_df, wheel_type == "PTW") |>
  pull(weight_tons) |>
  sum()
```

The total number of cigarette butts collected by Gwynnda in July of 2021 are 16300.
```{r}
filter(Final_TW_df, wheel_type == "GTW", year == "2021", month == "July") |>
  pull(cigarette_butts) |>
  sum()
```

#Problem 3
Import, clean, and tidy the dataset of baseline demographics. 
Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r}
MCI_Base = 
  read_csv("data/MCI_baseline.csv", skip = 1, na = c(".")) |>
  janitor::clean_names() |>
  mutate(sex = case_match(sex, 1 ~ "male", 0 ~ "female"),
         apoe4 = case_match(apoe4, 1 ~ "positive", 0 ~ "negative"))

MCI_Base
```
There are 483 individuals at first.

Discuss important steps in the import process and relevant features of the dataset.
1. import the data and clean names.
2. drop participants who do not meet the stated inclusion criteria
3. mutate sex and APOE4 carrier status to make sure they are not numeric.

```{r}
MCI_Base_1 = 
  MCI_Base |>
  filter(age_at_onset - current_age > 0 | is.na(age_at_onset))

MCI_Base_1
```
How many participants were recruited, and of these how many developed MCI?
There are 479 individuals when we remove the individuals who already have MCI at baseline. 

```{r}
MCI_Base_2 = 
  MCI_Base |>
  filter(age_at_onset - current_age > 0)

MCI_Base_2
```
How many participants were recruited, and of these how many developed MCI?
There are 93 individuals who developed MCI.

```{r}
mean(MCI_Base_1$current_age)
```
What is the average baseline age?
The average baseline age is 65 years old.

```{r}
nrow(filter(MCI_Base_1, apoe4 == "positive", sex == "female")) /
  nrow(filter(MCI_Base_1, sex == "female"))
```
What proportion of women in the study are APOE4 carriers?
0.3 of women in the study are APOE4 carriers

```{r}
MCI_Amy = 
  read_csv("data/MCI_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(time_0 = baseline, id = study_id) |>
  pivot_longer(time_0:time_8,
               names_to = "follow_up_time",
               values_to = "apoe4")

MCI_Amy
```
Discuss important steps in the import process and relevant features of the dataset.
1. import the data and clean names.
2. rename baseline to time_0 for consistency
3. use pivot_longer to tidy the data
There are total of 2435 observations in the data MCI_Amy.

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings.
Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

```{r}
Baseline = anti_join(MCI_Base_1, MCI_Amy, by = "id")
Amy = anti_join(MCI_Amy, MCI_Base_1, by = "id")
Merge_MCI = inner_join(MCI_Base_1, MCI_Amy, by = "id")

Baseline
Amy
Merge_MCI
```
There are 8 participants in the baseline data but not in the amyloid data.
(ID: 14, 49, 92, 179, 268, 304, 389, 412)
There are 16 participants in the amyloid data but no in the baseline data.
(ID: 72, 234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495)
There are 2355 observations appeared in both data sets, which means that there are 2355/5=471 participants.

```{r}
write.csv(Merge_MCI, "Merge_MCI.csv")
```
